"""
analyse_complete.py
Script principal pour l'analyse compl√®te des donn√©es CSV.
Orchestre toutes les analyses et g√©n√®re un rapport de synth√®se.
"""
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Configuration
EXTRACTED_CSV_DIR = '../extracted_csv'
RESULTS_DIR = '../exploration_results'
COMPLETE_DIR = 'analyse_complete'

def create_complete_directory():
    """Cr√©e le dossier pour l'analyse compl√®te."""
    os.makedirs(COMPLETE_DIR, exist_ok=True)

def load_and_summarize_data(csv_path):
    """Charge et r√©sume les donn√©es d'un fichier CSV."""
    try:
        # Charger un √©chantillon pour l'analyse
        df = pd.read_csv(csv_path, nrows=10000)
        
        # Informations de base
        summary = {
            'file_path': str(csv_path),
            'file_name': os.path.basename(csv_path),
            'file_size_mb': os.path.getsize(csv_path) / (1024 * 1024),
            'total_rows': len(df),
            'total_columns': len(df.columns),
            'memory_usage_mb': df.memory_usage(deep=True).sum() / (1024 * 1024),
            'missing_data_percentage': (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100
        }
        
        # Types de donn√©es
        dtype_counts = df.dtypes.value_counts()
        summary['data_types'] = dtype_counts.to_dict()
        
        # Colonnes par type
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
        datetime_cols = []
        
        # D√©tecter les colonnes de dates
        for col in df.columns:
            try:
                pd.to_datetime(df[col].head(100), errors='raise')
                datetime_cols.append(col)
            except:
                pass
        
        summary['numeric_columns'] = numeric_cols
        summary['categorical_columns'] = categorical_cols
        summary['datetime_columns'] = datetime_cols
        
        # Statistiques descriptives pour les variables num√©riques
        if numeric_cols:
            numeric_stats = df[numeric_cols].describe()
            summary['numeric_statistics'] = numeric_stats.to_dict()
        
        return df, summary
        
    except Exception as e:
        print(f"Erreur lors du chargement de {csv_path}: {e}")
        return None, None

def create_overview_visualizations(df, filename):
    """Cr√©e des visualisations d'aper√ßu g√©n√©ral."""
    # 1. Heatmap des valeurs manquantes
    plt.figure(figsize=(12, 8))
    sns.heatmap(df.isnull(), cbar=True, yticklabels=False, cmap='viridis')
    plt.title(f'Valeurs manquantes - {filename}')
    plt.tight_layout()
    plt.savefig(os.path.join(COMPLETE_DIR, f'{filename}_missing_values.png'), dpi=300)
    plt.close()
    
    # 2. Distribution des types de donn√©es
    dtype_counts = df.dtypes.value_counts()
    plt.figure(figsize=(10, 6))
    plt.pie(dtype_counts.values, labels=dtype_counts.index, autopct='%1.1f%%')
    plt.title(f'R√©partition des types de donn√©es - {filename}')
    plt.savefig(os.path.join(COMPLETE_DIR, f'{filename}_data_types.png'), dpi=300)
    plt.close()
    
    # 3. Corr√©lation des variables num√©riques (si applicable)
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) >= 2:
        corr_matrix = df[numeric_cols].corr()
        plt.figure(figsize=(12, 10))
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, square=True, fmt='.2f')
        plt.title(f'Matrice de corr√©lation - {filename}')
        plt.tight_layout()
        plt.savefig(os.path.join(COMPLETE_DIR, f'{filename}_correlation_matrix.png'), dpi=300)
        plt.close()

def generate_comprehensive_report(all_summaries, filename):
    """G√©n√®re un rapport complet d'analyse."""
    report_path = os.path.join(COMPLETE_DIR, f'{filename}_comprehensive_report.txt')
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(f"RAPPORT D'ANALYSE COMPL√àTE - {filename}\n")
        f.write("=" * 60 + "\n\n")
        
        # Informations g√©n√©rales
        f.write(f"üìä INFORMATIONS G√âN√âRALES\n")
        f.write(f"Fichier analys√© : {all_summaries['file_name']}\n")
        f.write(f"Taille du fichier : {all_summaries['file_size_mb']:.2f} MB\n")
        f.write(f"Nombre de lignes analys√©es : {all_summaries['total_rows']:,}\n")
        f.write(f"Nombre de colonnes : {all_summaries['total_columns']}\n")
        f.write(f"Utilisation m√©moire : {all_summaries['memory_usage_mb']:.2f} MB\n")
        f.write(f"Pourcentage de donn√©es manquantes : {all_summaries['missing_data_percentage']:.2f}%\n\n")
        
        # Types de donn√©es
        f.write(f"üìã TYPES DE DONN√âES\n")
        for dtype, count in all_summaries['data_types'].items():
            f.write(f"  - {dtype}: {count} colonne(s)\n")
        f.write("\n")
        
        # R√©partition des colonnes
        f.write(f"üîç R√âPARTITION DES COLONNES\n")
        f.write(f"  - Variables num√©riques : {len(all_summaries['numeric_columns'])}\n")
        f.write(f"  - Variables cat√©gorielles : {len(all_summaries['categorical_columns'])}\n")
        f.write(f"  - Variables temporelles : {len(all_summaries['datetime_columns'])}\n\n")
        
        # Variables num√©riques
        if all_summaries['numeric_columns']:
            f.write(f"üìà VARIABLES NUM√âRIQUES\n")
            f.write(f"Colonnes : {', '.join(all_summaries['numeric_columns'])}\n\n")
            
            if 'numeric_statistics' in all_summaries:
                f.write(f"Statistiques descriptives :\n")
                stats = all_summaries['numeric_statistics']
                for col in all_summaries['numeric_columns']:
                    if col in stats:
                        f.write(f"  {col}:\n")
                        f.write(f"    - Moyenne : {stats[col].get('mean', 'N/A'):.2f}\n")
                        f.write(f"    - M√©diane : {stats[col].get('50%', 'N/A'):.2f}\n")
                        f.write(f"    - √âcart-type : {stats[col].get('std', 'N/A'):.2f}\n")
                        f.write(f"    - Min : {stats[col].get('min', 'N/A'):.2f}\n")
                        f.write(f"    - Max : {stats[col].get('max', 'N/A'):.2f}\n\n")
        
        # Variables cat√©gorielles
        if all_summaries['categorical_columns']:
            f.write(f"üìä VARIABLES CAT√âGORIELLES\n")
            f.write(f"Colonnes : {', '.join(all_summaries['categorical_columns'])}\n\n")
        
        # Variables temporelles
        if all_summaries['datetime_columns']:
            f.write(f"üìÖ VARIABLES TEMPORELLES\n")
            f.write(f"Colonnes : {', '.join(all_summaries['datetime_columns'])}\n\n")
        
        # Recommandations
        f.write(f"üí° RECOMMANDATIONS D'ANALYSE\n")
        
        if all_summaries['numeric_columns']:
            f.write(f"  ‚úÖ Analyser les corr√©lations entre variables num√©riques\n")
            f.write(f"  ‚úÖ D√©tecter les outliers dans les variables num√©riques\n")
            f.write(f"  ‚úÖ Analyser les distributions des variables num√©riques\n")
        
        if all_summaries['categorical_columns']:
            f.write(f"  ‚úÖ Analyser les distributions des variables cat√©gorielles\n")
            f.write(f"  ‚úÖ Effectuer des tests de chi-carr√© entre variables cat√©gorielles\n")
        
        if all_summaries['datetime_columns'] and all_summaries['numeric_columns']:
            f.write(f"  ‚úÖ Analyser les tendances temporelles\n")
            f.write(f"  ‚úÖ D√©tecter la saisonnalit√© dans les donn√©es\n")
        
        if all_summaries['missing_data_percentage'] > 10:
            f.write(f"  ‚ö†Ô∏è Traiter les valeurs manquantes ({all_summaries['missing_data_percentage']:.1f}%)\n")
        
        f.write(f"\nüìÅ FICHIERS G√âN√âR√âS :\n")
        f.write(f"  - Valeurs manquantes : {filename}_missing_values.png\n")
        f.write(f"  - Types de donn√©es : {filename}_data_types.png\n")
        if all_summaries['numeric_columns']:
            f.write(f"  - Matrice de corr√©lation : {filename}_correlation_matrix.png\n")
        f.write(f"  - Rapport complet : {filename}_comprehensive_report.txt\n")
    
    print(f"‚úÖ Rapport complet g√©n√©r√© : {report_path}")

def run_complete_analysis(csv_path):
    """Ex√©cute une analyse compl√®te d'un fichier CSV."""
    filename = os.path.splitext(os.path.basename(csv_path))[0]
    print(f"üîç Analyse compl√®te de {filename}...")
    
    # Charger et r√©sumer les donn√©es
    df, summary = load_and_summarize_data(csv_path)
    
    if df is None or summary is None:
        return False
    
    # Cr√©er les visualisations d'aper√ßu
    create_overview_visualizations(df, filename)
    
    # G√©n√©rer le rapport complet
    generate_comprehensive_report(summary, filename)
    
    return True

def generate_master_summary(all_files_summaries):
    """G√©n√®re un r√©sum√© ma√Ætre de toutes les analyses."""
    master_path = os.path.join(COMPLETE_DIR, "00_master_summary.txt")
    
    with open(master_path, 'w', encoding='utf-8') as f:
        f.write("R√âSUM√â MA√éTRE - ANALYSE COMPL√àTE DES DONN√âES\n")
        f.write("=" * 60 + "\n\n")
        
        f.write(f"üìä SYNTH√àSE G√âN√âRALE\n")
        f.write(f"Nombre de fichiers analys√©s : {len(all_files_summaries)}\n")
        f.write(f"Date d'analyse : {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        total_rows = sum(s['total_rows'] for s in all_files_summaries)
        total_columns = sum(s['total_columns'] for s in all_files_summaries)
        total_size = sum(s['file_size_mb'] for s in all_files_summaries)
        
        f.write(f"üìà STATISTIQUES GLOBALES\n")
        f.write(f"  - Total de lignes : {total_rows:,}\n")
        f.write(f"  - Total de colonnes : {total_columns}\n")
        f.write(f"  - Taille totale : {total_size:.2f} MB\n")
        f.write(f"  - Moyenne de lignes par fichier : {total_rows/len(all_files_summaries):.0f}\n")
        f.write(f"  - Moyenne de colonnes par fichier : {total_columns/len(all_files_summaries):.1f}\n\n")
        
        f.write(f"üìã D√âTAIL PAR FICHIER\n")
        for summary in all_files_summaries:
            f.write(f"\n{summary['file_name']}:\n")
            f.write(f"  - Taille : {summary['file_size_mb']:.2f} MB\n")
            f.write(f"  - Lignes : {summary['total_rows']:,}\n")
            f.write(f"  - Colonnes : {summary['total_columns']}\n")
            f.write(f"  - Num√©riques : {len(summary['numeric_columns'])}\n")
            f.write(f"  - Cat√©gorielles : {len(summary['categorical_columns'])}\n")
            f.write(f"  - Temporelles : {len(summary['datetime_columns'])}\n")
            f.write(f"  - Donn√©es manquantes : {summary['missing_data_percentage']:.1f}%\n")
        
        f.write(f"\nüéØ RECOMMANDATIONS GLOBALES\n")
        f.write(f"  ‚úÖ Ex√©cuter analyse_statistique.py pour les corr√©lations et outliers\n")
        f.write(f"  ‚úÖ Ex√©cuter analyse_categorielle.py pour les variables cat√©gorielles\n")
        f.write(f"  ‚úÖ Ex√©cuter analyse_temporelle.py pour les s√©ries temporelles\n")
        f.write(f"  ‚úÖ Consulter les rapports individuels pour chaque fichier\n")
    
    print(f"üìã R√©sum√© ma√Ætre g√©n√©r√© : {master_path}")

def main():
    """Fonction principale pour l'analyse compl√®te."""
    print("üöÄ D√©but de l'analyse compl√®te des donn√©es...")
    
    # Cr√©er le dossier de r√©sultats
    create_complete_directory()
    
    # Lister les fichiers CSV
    extracted_dir = Path(EXTRACTED_CSV_DIR)
    if not extracted_dir.exists():
        print(f"‚ùå Le dossier {EXTRACTED_CSV_DIR} n'existe pas.")
        print("üí° Veuillez d'abord ex√©cuter extract.py pour extraire les fichiers compress√©s.")
        print("   Commande : python ../etl_steps/extract.py")
        return
    
    csv_files = list(extracted_dir.rglob("*.csv"))
    
    if not csv_files:
        print("‚ùå Aucun fichier CSV trouv√©.")
        print("üí° Veuillez d'abord ex√©cuter extract.py pour extraire les fichiers compress√©s.")
        print("   Commande : python ../etl_steps/extract.py")
        return
    
    print(f"üìÅ {len(csv_files)} fichier(s) CSV trouv√©(s)")
    
    # Analyser chaque fichier
    all_summaries = []
    successful_analyses = 0
    
    for csv_path in csv_files:
        try:
            # Charger et r√©sumer les donn√©es
            df, summary = load_and_summarize_data(csv_path)
            
            if df is not None and summary is not None:
                filename = os.path.splitext(os.path.basename(csv_path))[0]
                
                # Cr√©er les visualisations d'aper√ßu
                create_overview_visualizations(df, filename)
                
                # G√©n√©rer le rapport complet
                generate_comprehensive_report(summary, filename)
                
                all_summaries.append(summary)
                successful_analyses += 1
                
        except Exception as e:
            print(f"‚ùå Erreur lors de l'analyse de {csv_path}: {e}")
    
    # G√©n√©rer le r√©sum√© ma√Ætre
    if all_summaries:
        generate_master_summary(all_summaries)
    
    print(f"\n‚úÖ Analyse compl√®te termin√©e !")
    print(f"   - Fichiers analys√©s : {successful_analyses}/{len(csv_files)}")
    print(f"   - R√©sultats dans : {COMPLETE_DIR}")
    print(f"\nüìã Prochaines √©tapes recommand√©es :")
    print(f"   1. Consulter le r√©sum√© ma√Ætre : {COMPLETE_DIR}/00_master_summary.txt")
    print(f"   2. Ex√©cuter analyse_statistique.py pour les analyses avanc√©es")
    print(f"   3. Ex√©cuter analyse_categorielle.py pour les variables cat√©gorielles")
    print(f"   4. Ex√©cuter analyse_temporelle.py pour les s√©ries temporelles")

if __name__ == "__main__":
    main() 