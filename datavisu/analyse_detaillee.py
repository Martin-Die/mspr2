import pandas as pd
import numpy as np
from datetime import datetime

# Analyser le fichier CSV
csv_file = "../extracted_csv/2019-Oct.csv"

print("üéØ ANALYSE D√âTAILL√âE POUR LA FID√âLISATION CLIENT")
print("=" * 60)

# Lire un √©chantillon plus important
df = pd.read_csv(csv_file, nrows=50000)

print(f"üìä Donn√©es analys√©es : {len(df)} lignes")
print(f"üìÖ P√©riode : {df['event_time'].min()} √† {df['event_time'].max()}")

# Analyser les colonnes
print(f"\nüìã STRUCTURE DES DONN√âES :")
print(f"Colonnes disponibles ({len(df.columns)}):")
for i, col in enumerate(df.columns, 1):
    dtype = df[col].dtype
    missing_pct = (df[col].isna().sum() / len(df)) * 100
    unique_count = df[col].nunique()
    print(f"{i:2d}. {col} ({dtype}) - {missing_pct:.1f}% manquants - {unique_count} valeurs uniques")

# Analyser les types d'√©v√©nements
print(f"\nüéØ TYPES D'√âV√âNEMENTS (event_type):")
event_counts = df['event_type'].value_counts()
for event, count in event_counts.items():
    pct = (count / len(df)) * 100
    print(f"  - {event}: {count} ({pct:.1f}%)")

# Analyser les utilisateurs
print(f"\nüë• ANALYSE DES UTILISATEURS :")
user_stats = df.groupby('user_id').agg({
    'event_time': 'count',
    'price': ['sum', 'mean'],
    'event_type': 'nunique'
}).round(2)

user_stats.columns = ['nb_events', 'total_spent', 'avg_price', 'nb_event_types']
print(f"  - Nombre d'utilisateurs uniques : {df['user_id'].nunique()}")
print(f"  - √âv√©nements par utilisateur : {user_stats['nb_events'].mean():.1f} (moyenne)")
print(f"  - D√©penses par utilisateur : {user_stats['total_spent'].mean():.2f} (moyenne)")
print(f"  - Types d'√©v√©nements par utilisateur : {user_stats['nb_event_types'].mean():.1f} (moyenne)")

# Analyser les produits et cat√©gories
print(f"\nüõçÔ∏è ANALYSE DES PRODUITS :")
print(f"  - Nombre de produits uniques : {df['product_id'].nunique()}")
print(f"  - Nombre de cat√©gories : {df['category_id'].nunique()}")
print(f"  - Nombre de marques : {df['brand'].nunique()}")

# Analyser les prix
print(f"\nüí∞ ANALYSE DES PRIX :")
print(f"  - Prix moyen : {df['price'].mean():.2f}")
print(f"  - Prix m√©dian : {df['price'].median():.2f}")
print(f"  - Prix min : {df['price'].min():.2f}")
print(f"  - Prix max : {df['price'].max():.2f}")

# Identifier les variables pour la fid√©lisation
print(f"\nüéØ VARIABLES POUR LA FID√âLISATION :")

# Variables cibles potentielles (√† cr√©er)
print(f"üìä Variables cibles √† cr√©er :")
print(f"  1. CHURN : Bas√© sur l'inactivit√© des utilisateurs")
print(f"  2. LIFETIME_VALUE : Valeur totale par utilisateur")
print(f"  3. ENGAGEMENT_SCORE : Fr√©quence d'activit√©")
print(f"  4. PURCHASE_FREQUENCY : Fr√©quence d'achat")
print(f"  5. CUSTOMER_SEGMENT : Segment bas√© sur RFM")

# Variables pr√©dictives disponibles
print(f"\nüìà Variables pr√©dictives disponibles :")
print(f"  ‚úÖ user_id : Identifiant client")
print(f"  ‚úÖ event_type : Type d'interaction")
print(f"  ‚úÖ product_id : Produits consult√©s/achet√©s")
print(f"  ‚úÖ category_id : Cat√©gories pr√©f√©r√©es")
print(f"  ‚úÖ brand : Marques pr√©f√©r√©es")
print(f"  ‚úÖ price : Comportement de prix")
print(f"  ‚úÖ event_time : Patterns temporels")
print(f"  ‚úÖ user_session : Sessions utilisateur")

# Recommandations pour le mod√®le
print(f"\nü§ñ RECOMMANDATIONS POUR LE MOD√àLE IA :")

print(f"1. VARIABLES CIBLES √Ä CR√âER :")
print(f"   - CHURN_BINARY : 1 si utilisateur inactif > 30 jours")
print(f"   - CUSTOMER_VALUE : Somme totale des achats")
print(f"   - ENGAGEMENT_LEVEL : Bas√© sur la fr√©quence d'√©v√©nements")
print(f"   - PURCHASE_INTENT : Probabilit√© d'achat")

print(f"\n2. FEATURES √Ä CR√âER :")
print(f"   - RFM_SCORE : Recency, Frequency, Monetary")
print(f"   - PRODUCT_PREFERENCES : Cat√©gories/marques pr√©f√©r√©es")
print(f"   - PRICE_SENSITIVITY : Comportement face aux prix")
print(f"   - ACTIVITY_PATTERNS : Patterns temporels")
print(f"   - SESSION_BEHAVIOR : Comportement par session")

print(f"\n3. ALGORITHMES RECOMMAND√âS :")
print(f"   - Classification : Random Forest, XGBoost pour le churn")
print(f"   - R√©gression : Linear Regression, Random Forest pour LTV")
print(f"   - Clustering : K-Means pour la segmentation")

print(f"\n4. M√âTRIQUES DE PERFORMANCE :")
print(f"   - Pour le churn : Precision, Recall, F1-Score")
print(f"   - Pour LTV : RMSE, MAE, R¬≤")
print(f"   - Pour segmentation : Silhouette Score")

print(f"\n5. PROCHAINES √âTAPES :")
print(f"   1. Cr√©er les variables cibles (churn, LTV)")
print(f"   2. Feature engineering (RFM, pr√©f√©rences)")
print(f"   3. Entra√Æner les mod√®les de pr√©diction")
print(f"   4. Valider et optimiser les performances")
print(f"   5. D√©ployer le syst√®me de fid√©lisation")

# Exemple de cr√©ation de features
print(f"\nüí° EXEMPLE DE FEATURES √Ä CR√âER :")

# Calculer quelques statistiques par utilisateur
user_features = df.groupby('user_id').agg({
    'event_time': ['count', 'min', 'max'],
    'price': ['sum', 'mean', 'std'],
    'event_type': 'nunique',
    'product_id': 'nunique',
    'category_id': 'nunique',
    'brand': 'nunique'
}).round(2)

user_features.columns = ['total_events', 'first_event', 'last_event', 
                        'total_spent', 'avg_price', 'price_std',
                        'event_types', 'products_viewed', 'categories_viewed', 'brands_viewed']

print(f"Features calcul√©es pour {len(user_features)} utilisateurs :")
print(user_features.head())

print(f"\n‚úÖ ANALYSE TERMIN√âE - Pr√™t pour la mod√©lisation IA !") 